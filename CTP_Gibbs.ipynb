{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CTP using Gibb's sampling\n",
    "\n",
    "LDA deel op basis van uitleg in http://u.cs.biu.ac.il/~89-680/darling-lda.pdf\n",
    "\n",
    "Using Gensim functionality\n",
    "\n",
    "Dus we mogen ervan uitgaan dat we een dictionary hebben en bow vectors voor de documenten.\n",
    "Het een en ander aan counts komt dan uit gensim. Maar hoe?\n",
    "\n",
    "Wat hebben we nodig (LDA deel)?\n",
    "\n",
    "* The number of words assigned to topic k in document d: $$n_{d;k}$$\n",
    "* The number of times word w is assigned to topic k: $$n_{k;w}$$\n",
    "* The total number of times any word is assigned to topic k: $$n_k$$\n",
    "* Array z which will contain the current topic assignment for each of the N words in the corpus.\n",
    "\n",
    "We beginnen met 1 extra perspectief (misschien perspectief-klasse?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate documents\n",
    "import numpy as np\n",
    "\n",
    "length_topic = 50\n",
    "length_opinion = 20\n",
    "num_topics = 3\n",
    "topic_vocabulary = np.array(['zon', 'ijs', 'strand', 'vanille', 'chocola', 'broccoli', 'wortel'])\n",
    "opinion_vocabulary = np.array(['warm', 'zwemmen', 'zonnig', 'bewolkt', 'vies', 'lekker', 'koud'])\n",
    "\n",
    "real_theta_topic = np.array([[1.0, 0.0, 0.0],\n",
    "                             [0.0, 1.0, 0.0],\n",
    "                             [0.0, 0.0, 1.0],\n",
    "                             [0.5, 0.5, 0.0],\n",
    "                             [0.0, 0.5, 0.5]])\n",
    "real_phi_topic = np.array([[0.4, 0.2, 0.4, 0.0, 0.0, 0.0, 0.0],\n",
    "                           [0.0, 0.3, 0.0, 0.35, 0.35, 0.0, 0.0],\n",
    "                           [0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.5]])\n",
    "real_phi_opinion = np.array([[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "                             [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n",
    "                             [0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document 1 {'topic': ['zon', 'strand', 'zon', 'ijs', 'ijs', 'zon', 'zon', 'ijs', 'zon', 'strand', 'zon', 'zon', 'strand', 'strand', 'strand', 'zon', 'ijs', 'strand', 'ijs', 'strand', 'ijs', 'strand', 'strand', 'strand', 'strand', 'ijs', 'zon', 'zon', 'ijs', 'ijs', 'ijs', 'zon', 'ijs', 'strand', 'strand', 'zon', 'ijs', 'ijs', 'strand', 'ijs', 'strand', 'strand', 'zon', 'zon', 'strand', 'ijs', 'ijs', 'strand', 'strand', 'strand'], 'opinion': ['warm', 'warm', 'warm', 'warm', 'warm', 'warm', 'warm', 'warm', 'warm', 'warm', 'warm', 'warm', 'warm', 'warm', 'warm', 'warm', 'warm', 'warm', 'warm', 'warm']}\n",
      "document 2 {'topic': ['chocola', 'vanille', 'vanille', 'chocola', 'ijs', 'ijs', 'vanille', 'vanille', 'vanille', 'vanille', 'chocola', 'ijs', 'ijs', 'vanille', 'vanille', 'ijs', 'ijs', 'vanille', 'ijs', 'vanille', 'chocola', 'chocola', 'ijs', 'vanille', 'chocola', 'vanille', 'chocola', 'chocola', 'chocola', 'chocola', 'chocola', 'chocola', 'chocola', 'chocola', 'chocola', 'chocola', 'vanille', 'vanille', 'vanille', 'vanille', 'ijs', 'chocola', 'ijs', 'vanille', 'ijs', 'chocola', 'vanille', 'vanille', 'chocola', 'vanille'], 'opinion': ['koud', 'koud', 'koud', 'koud', 'koud', 'koud', 'koud', 'koud', 'koud', 'koud', 'koud', 'koud', 'koud', 'koud', 'koud', 'koud', 'koud', 'koud', 'koud', 'koud']}\n",
      "document 3 {'topic': ['broccoli', 'broccoli', 'broccoli', 'broccoli', 'wortel', 'wortel', 'broccoli', 'wortel', 'wortel', 'wortel', 'wortel', 'broccoli', 'broccoli', 'broccoli', 'broccoli', 'broccoli', 'broccoli', 'wortel', 'wortel', 'broccoli', 'broccoli', 'broccoli', 'wortel', 'wortel', 'wortel', 'wortel', 'broccoli', 'wortel', 'wortel', 'wortel', 'broccoli', 'broccoli', 'broccoli', 'broccoli', 'broccoli', 'broccoli', 'wortel', 'wortel', 'broccoli', 'broccoli', 'broccoli', 'wortel', 'broccoli', 'broccoli', 'wortel', 'broccoli', 'broccoli', 'wortel', 'wortel', 'wortel'], 'opinion': ['vies', 'vies', 'vies', 'vies', 'vies', 'vies', 'vies', 'vies', 'vies', 'vies', 'vies', 'vies', 'vies', 'vies', 'vies', 'vies', 'vies', 'vies', 'vies', 'vies']}\n",
      "document 4 {'topic': ['ijs', 'strand', 'ijs', 'strand', 'strand', 'vanille', 'strand', 'ijs', 'vanille', 'vanille', 'chocola', 'vanille', 'ijs', 'zon', 'vanille', 'zon', 'ijs', 'zon', 'ijs', 'chocola', 'ijs', 'vanille', 'vanille', 'strand', 'vanille', 'ijs', 'ijs', 'chocola', 'chocola', 'vanille', 'ijs', 'ijs', 'chocola', 'strand', 'ijs', 'ijs', 'ijs', 'vanille', 'ijs', 'zon', 'ijs', 'ijs', 'ijs', 'chocola', 'strand', 'zon', 'chocola', 'zon', 'zon', 'vanille'], 'opinion': ['koud', 'warm', 'warm', 'koud', 'koud', 'koud', 'koud', 'warm', 'koud', 'koud', 'koud', 'koud', 'koud', 'warm', 'koud', 'warm', 'warm', 'koud', 'koud', 'koud']}\n",
      "document 5 {'topic': ['chocola', 'chocola', 'broccoli', 'vanille', 'broccoli', 'ijs', 'wortel', 'vanille', 'wortel', 'broccoli', 'ijs', 'wortel', 'wortel', 'broccoli', 'ijs', 'ijs', 'wortel', 'broccoli', 'wortel', 'wortel', 'wortel', 'wortel', 'chocola', 'chocola', 'wortel', 'wortel', 'ijs', 'broccoli', 'wortel', 'ijs', 'vanille', 'wortel', 'broccoli', 'ijs', 'wortel', 'wortel', 'wortel', 'wortel', 'broccoli', 'broccoli', 'vanille', 'ijs', 'chocola', 'chocola', 'ijs', 'ijs', 'wortel', 'broccoli', 'broccoli', 'wortel'], 'opinion': ['vies', 'vies', 'koud', 'vies', 'koud', 'koud', 'koud', 'vies', 'vies', 'vies', 'vies', 'koud', 'vies', 'vies', 'vies', 'vies', 'koud', 'vies', 'koud', 'vies']}\n"
     ]
    }
   ],
   "source": [
    "# generate the corpus\n",
    "from collections import Counter\n",
    "\n",
    "corpus = []\n",
    "\n",
    "for m, tm in enumerate(real_theta_topic):\n",
    "    doc = {'topic': [], 'opinion': []}\n",
    "    topic_counter = Counter()\n",
    "    for i in range(length_topic):\n",
    "        # topic words\n",
    "        topic = np.random.multinomial(1, tm)\n",
    "        topic_index = np.where(topic==1)[0][0]\n",
    "        topic_counter[topic_index] += 1\n",
    "        word = np.random.multinomial(1, real_phi_topic[topic_index])\n",
    "        doc['topic'].append(topic_vocabulary[np.where(word==1)[0][0]])\n",
    "    \n",
    "    #print topic_counter\n",
    "    \n",
    "    # select opinion (index) based on topic occurrence\n",
    "    om = np.array([float(topic_counter[i]) for i in range(num_topics)])\n",
    "    #print om\n",
    "    # normalize\n",
    "    om /= sum(om)\n",
    "    for i in range(length_opinion):\n",
    "        # opinion words\n",
    "        topic = np.random.multinomial(1, om)\n",
    "        topic_index = np.where(topic==1)[0][0]\n",
    "        #print topic_index, real_phi_opinion[topic_index]\n",
    "        word = np.random.multinomial(1, real_phi_opinion[topic_index])\n",
    "        #print opinion_vocabulary[np.where(word==1)[0][0]]\n",
    "        doc['opinion'].append(opinion_vocabulary[np.where(word==1)[0][0]])\n",
    "        \n",
    "    corpus.append(doc)\n",
    "    \n",
    "for i, doc in enumerate(corpus):\n",
    "    print 'document', i+1, doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "\n",
    "d = corpora.Dictionary(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{(1, 17): 0, (0, 7): 0, (1, 6): 0, (0, 10): 1, (3, 7): 1, (2, 5): 1, (1, 11): 2, (4, 0): 1, (4, 19): 1, (0, 17): 2, (0, 4): 2, (1, 1): 1, (4, 10): 2, (3, 2): 0, (2, 6): 2, (4, 5): 0, (4, 16): 1, (2, 17): 1, (0, 1): 2, (3, 12): 1, (1, 12): 2, (4, 15): 2, (3, 1): 2, (2, 11): 2, (3, 18): 2, (2, 18): 0, (0, 14): 1, (3, 11): 2, (2, 1): 1, (1, 15): 1, (4, 12): 2, (2, 12): 0, (3, 17): 2, (1, 16): 0, (1, 5): 0, (0, 11): 0, (3, 6): 2, (2, 2): 0, (1, 10): 1, (4, 1): 2, (0, 18): 0, (1, 19): 1, (0, 5): 0, (1, 0): 0, (0, 8): 1, (4, 11): 0, (3, 5): 0, (2, 7): 0, (4, 6): 2, (4, 17): 0, (0, 2): 2, (3, 15): 2, (1, 3): 0, (4, 8): 1, (3, 0): 2, (2, 8): 1, (2, 19): 2, (0, 15): 0, (3, 10): 2, (1, 14): 1, (4, 13): 0, (2, 13): 1, (3, 16): 0, (1, 4): 0, (0, 12): 0, (3, 9): 0, (2, 3): 0, (1, 9): 0, (4, 2): 0, (2, 14): 1, (0, 19): 2, (1, 18): 2, (0, 6): 0, (1, 7): 2, (0, 9): 1, (3, 4): 2, (2, 4): 0, (4, 7): 0, (4, 18): 1, (0, 16): 0, (0, 3): 1, (3, 14): 2, (1, 2): 0, (4, 9): 0, (3, 3): 0, (2, 9): 1, (4, 4): 0, (2, 16): 1, (0, 0): 0, (3, 13): 0, (1, 13): 1, (4, 14): 0, (2, 10): 0, (3, 19): 0, (0, 13): 1, (3, 8): 0, (2, 0): 2, (1, 8): 0, (4, 3): 1, (2, 15): 2}\n",
      "[[ 9  6  5]\n",
      " [10  6  4]\n",
      " [ 7  8  5]\n",
      " [ 8  2 10]\n",
      " [ 9  6  5]]\n",
      "[[12  0  0  0 12  0 19]\n",
      " [ 7  0  0  0 12  0  9]\n",
      " [ 7  0  0  0  9  0 13]]\n",
      "[50 50 50 50 50]\n",
      "Counter({1: 90, 2: 90, 0: 70}) Counter({0: 43, 2: 29, 1: 28})\n"
     ]
    }
   ],
   "source": [
    "# initialize z and o\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "# topic\n",
    "z = {}\n",
    "ndk = np.zeros((len(corpus), num_topics), dtype=np.int)\n",
    "nkw = np.zeros((num_topics, len(topic_vocabulary)), dtype=np.int)\n",
    "nk = Counter()\n",
    "\n",
    "# opinion\n",
    "x = {}\n",
    "nsd = np.zeros((len(corpus), num_topics), dtype=np.int)\n",
    "nrs = np.zeros((num_topics, len(opinion_vocabulary)), dtype=np.int)\n",
    "ntd = np.zeros(len(corpus), dtype=np.int)\n",
    "ns = Counter()\n",
    "\n",
    "for d, doc in enumerate(corpus):\n",
    "    for i, word in enumerate(doc['topic']):\n",
    "        t = random.randint(0,2)\n",
    "        z[(d, i)] = t\n",
    "        ndk[d][t] += 1\n",
    "        word_index = np.where(topic_vocabulary==word)[0][0]\n",
    "        nkw[t][word_index] += 1\n",
    "        nk[t] += 1\n",
    "        ntd[d] += 1\n",
    "    for i, word in enumerate(doc['opinion']):\n",
    "        o = random.randint(0,2)\n",
    "        x[(d, i)] = o\n",
    "        nsd[d][o] += 1\n",
    "        word_index = np.where(opinion_vocabulary==word)[0][0]\n",
    "        nrs[o][word_index] += 1\n",
    "        ns[o] += 1\n",
    "\n",
    "#print z\n",
    "#print ndk\n",
    "#print np.sum(ndk)\n",
    "#print nkw\n",
    "#print np.sum(nkw)\n",
    "#print nk\n",
    "print x\n",
    "print nsd\n",
    "print nrs\n",
    "print ntd\n",
    "print nk, ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0 50]\n",
      " [50  0  0]\n",
      " [ 0 50  0]\n",
      " [33  0 17]\n",
      " [20 30  0]]\n",
      "[[ 0 36  0 35 32  0  0]\n",
      " [ 0  0  0  0  0 39 41]\n",
      " [21 19 27  0  0  0  0]]\n",
      "Counter({0: 103, 1: 80, 2: 67})\n",
      "[[26  0  0  0  0  0 14]\n",
      " [ 0  0  0  0  0  0  1]\n",
      " [ 0  0  0  0 33  0 26]]\n",
      "Counter({2: 59, 0: 40, 1: 1})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/kernel/__main__.py:19: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/usr/local/lib/python2.7/dist-packages/IPython/kernel/__main__.py:21: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "# iterate\n",
    "#np.seterr(all='raise')\n",
    "\n",
    "def p_z(alpha, beta, num_topics, num_words, d, topic, word_index):\n",
    "    #print alpha, beta, num_topics, num_words, d, topic, word_index\n",
    "    #print ndk[d][topic], nkw[topic][word_index], nk[topic]\n",
    "    \n",
    "    # De formule voor p_z is anders in het uitgewerkte voorbeeld dan in paper 'Finding scientific topics' en in CTP paper \n",
    "    # die hier staat is die uit het uitgewerkte voorbeeld\n",
    "    return (ndk[d][topic]+alpha)*(nkw[topic][word_index]+beta)/(nk[topic]+beta*num_words)\n",
    "\n",
    "def p_z2(alpha, beta, num_topics, num_words, d, topic, word_index):\n",
    "    return ((ndk[d][topic]+alpha)/(np.sum(ndk[d])+num_topics*alpha)) * \\\n",
    "           (nkw[topic][word_index]+beta)/(nk[topic]+beta*num_words)\n",
    "\n",
    "\n",
    "def p_x(beta_o, num_opinion_words, d, opinion, word_index):\n",
    "    #print beta_o, num_opinion_words, d, opinion, word_index\n",
    "    #print nrs[opinion][word_index], nsd[d][opinion], ntd[d]\n",
    "    left = (nrs[opinion][word_index]+beta_o)/ns[o]+beta_o*num_opinion_words\n",
    "    right = (float(nsd[d][opinion])/ntd[d])\n",
    "    return left*right\n",
    "\n",
    "def normalize(p):\n",
    "    minimum = np.min(p)\n",
    "    maximum = np.max(p)\n",
    "    \n",
    "    if minimum < 0:\n",
    "        print '<0'\n",
    "        return normalize((p - minimum)/(maximum - minimum))\n",
    "    return p/sum(p)\n",
    "\n",
    "num_iter = 100\n",
    "\n",
    "alpha = 0.1\n",
    "beta = beta_o = 0.02\n",
    "\n",
    "theta = np.zeros((num_iter,  len(corpus), num_topics), dtype=np.float_)\n",
    "phi = np.zeros((num_iter, num_topics, len(topic_vocabulary)), dtype=np.float_)\n",
    "phi_o =np.zeros((num_iter, num_topics, len(opinion_vocabulary)), dtype=np.float_) \n",
    "\n",
    "for t in range(num_iter):\n",
    "    for d, doc in enumerate(corpus):\n",
    "        # Topic words\n",
    "        for i, w in enumerate(doc['topic']):\n",
    "            word = (d, i)\n",
    "            topic = z[word]\n",
    "            \n",
    "            word_index = np.where(topic_vocabulary==w)[0][0]\n",
    "            \n",
    "            #if ndk[d][topic] > 0 and nkw[topic][word_index] > 0 and nk[topic] > 0:\n",
    "            if True:\n",
    "                ndk[d][topic] -= 1\n",
    "                nkw[topic][word_index] -= 1\n",
    "                nk[topic] -= 1\n",
    "            \n",
    "                p = [p_z2(alpha, beta, len(real_phi_topic), len(topic_vocabulary), d, j, word_index) for j in range(num_topics)]\n",
    "                #print p\n",
    "                # normalize\n",
    "                p = normalize(p)\n",
    "                #print p, sum(p)\n",
    "            \n",
    "                to = np.random.multinomial(1, p)\n",
    "                topic = np.where(to==1)[0][0]\n",
    "                \n",
    "                z[word] = topic\n",
    "            \n",
    "                ndk[d][topic] += 1\n",
    "                nkw[topic][word_index] += 1\n",
    "                nk[topic] += 1\n",
    "\n",
    "        # Opinion words\n",
    "        for i, w in enumerate(doc['opinion']):\n",
    "            word = (d, i)\n",
    "            opinion = x[word]\n",
    "            \n",
    "            word_index = np.where(opinion_vocabulary==w)[0][0]\n",
    "            \n",
    "            nsd[d][opinion] -= 1\n",
    "            nrs[opinion][word_index] -= 1\n",
    "            ns[opinion] -= 1\n",
    "            \n",
    "            p = np.array([p_x(beta_o, len(opinion_vocabulary), d, j, word_index) for j in range(num_topics)], dtype=np.float)\n",
    "            #print p, \n",
    "            p = normalize(p)\n",
    "            #print p\n",
    "            opinion = np.random.multinomial(1, p).argmax()\n",
    "            #opinion = np.where(op==1)[0][0]\n",
    "            \n",
    "            x[word] = opinion\n",
    "            \n",
    "            nsd[d][opinion] += 1\n",
    "            nrs[opinion][word_index] += 1\n",
    "            ns[opinion] += 1\n",
    "        \n",
    "    # calculate theta and phi\n",
    "    theta[t] = (ndk+float(alpha))/(np.sum(ndk, axis=1, keepdims=True)+num_topics*alpha)\n",
    "    phi[t] = (nkw+float(beta))/(np.sum(nkw, axis=1, keepdims=True)+len(topic_vocabulary)*beta)    \n",
    "    phi_o[t] = (nrs+float(beta_o))/(np.sum(nrs, axis=1, keepdims=True)+len(opinion_vocabulary)*beta_o)\n",
    "            #print 'new topic', topic\n",
    "print ndk\n",
    "print nkw\n",
    "print nk\n",
    "print nrs\n",
    "print ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta\n",
      "found\n",
      "[[ 0.01073559  0.00437376  0.98489066]\n",
      " [ 0.98807157  0.00795229  0.00397614]\n",
      " [ 0.00357853  0.99304175  0.00337972]\n",
      " [ 0.54592445  0.00417495  0.4499006 ]\n",
      " [ 0.38866799  0.6         0.01133201]]\n",
      "real\n",
      "[[ 1.   0.   0. ]\n",
      " [ 0.   1.   0. ]\n",
      " [ 0.   0.   1. ]\n",
      " [ 0.5  0.5  0. ]\n",
      " [ 0.   0.5  0.5]]\n",
      "\n",
      "phi\n",
      "found\n",
      "[[  1.84446523e-03   3.07741933e-01   2.90573614e-03   3.57081507e-01\n",
      "    3.27949131e-01   6.34212374e-04   1.84301510e-03]\n",
      " [  4.42282903e-04   3.90244848e-03   6.36194091e-04   2.41400546e-03\n",
      "    1.86671274e-03   4.83797569e-01   5.06940787e-01]\n",
      " [  2.87205292e-01   3.38384339e-01   3.68730261e-01   1.97782981e-03\n",
      "    7.94017445e-04   9.23651876e-04   1.98460840e-03]]\n",
      "real\n",
      "[[ 0.4   0.2   0.4   0.    0.    0.    0.  ]\n",
      " [ 0.    0.3   0.    0.35  0.35  0.    0.  ]\n",
      " [ 0.    0.    0.    0.    0.    0.5   0.5 ]]\n",
      "\n",
      "topics found:\n",
      "['ijs' 'vanille' 'chocola']\n",
      "['broccoli' 'wortel']\n",
      "['zon' 'ijs' 'strand']\n",
      "\n",
      "topics real\n",
      "['zon' 'ijs' 'strand']\n",
      "['ijs' 'vanille' 'chocola']\n",
      "['broccoli' 'wortel']\n",
      "opinions found:\n",
      "['warm' 'koud']\n",
      "['warm' 'zwemmen' 'zonnig' 'bewolkt' 'vies' 'lekker' 'koud']\n",
      "['vies' 'koud']\n",
      "\n",
      "opinions real\n",
      "['warm']\n",
      "['koud']\n",
      "['vies']\n"
     ]
    }
   ],
   "source": [
    "print 'theta'\n",
    "print 'found'\n",
    "print np.mean(theta, axis=0)\n",
    "print 'real'\n",
    "print real_theta_topic\n",
    "print\n",
    "print 'phi'\n",
    "print 'found'\n",
    "print np.mean(phi, axis=0)\n",
    "print 'real'\n",
    "print real_phi_topic\n",
    "print\n",
    "print 'topics found:'\n",
    "indexes = np.mean(phi, axis=0) > 0.01\n",
    "for index in indexes:\n",
    "    print topic_vocabulary[index]\n",
    "print\n",
    "print 'topics real'\n",
    "indexes = real_phi_topic > 0.01\n",
    "for index in indexes:\n",
    "    print topic_vocabulary[index]\n",
    "print 'opinions found:'\n",
    "indexes = np.mean(phi_o, axis=0) > 0.01\n",
    "for index in indexes:\n",
    "    print opinion_vocabulary[index]\n",
    "print\n",
    "print 'opinions real'\n",
    "indexes = real_phi_opinion > 0.01\n",
    "for index in indexes:\n",
    "    print opinion_vocabulary[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('warm', 0.64248298080849353), ('koud', 0.35205398075466376), ('vies', 0.0034848311894939425), ('lekker', 0.00049455181183695517), ('bewolkt', 0.00049455181183695517), ('zonnig', 0.00049455181183695517), ('zwemmen', 0.00049455181183695517)]\n",
      "[('koud', 0.88700271544967546), ('vies', 0.025787147613644135), ('warm', 0.018007798250136348), ('lekker', 0.017300584671635637), ('bewolkt', 0.017300584671635637), ('zonnig', 0.017300584671635637), ('zwemmen', 0.017300584671635637)]\n",
      "[('vies', 0.5573144753999546), ('koud', 0.43980912627046043), ('warm', 0.0015055458262555261), ('lekker', 0.00034271312583213553), ('bewolkt', 0.00034271312583213553), ('zonnig', 0.00034271312583213553), ('zwemmen', 0.00034271312583213553)]\n"
     ]
    }
   ],
   "source": [
    "def print_topic(weights, words):\n",
    "    l = zip(words, weights)\n",
    "    l.sort(key=lambda tup: tup[1])\n",
    "    print l[::-1]\n",
    "\n",
    "for t in np.mean(phi_o, axis=0):\n",
    "    print_topic(t, opinion_vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is het toeval dat de indices van de topic topics en de opinion topics overeen komen of niet? En hoe kun je daarachter komen?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
